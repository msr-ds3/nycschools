---
title: "20170724_predicting_continuation_take_2"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Automated Guidance Counselor
##Predict if a student will continue to the next grade.

```{r cars}
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(boot)
library(glmnet)
library(tidyverse)
library(scales)
library(ROCR)

files <- Sys.glob('/data/nycdoe/June Biog/*.csv')

read_csv_with_year <- function(filename) {
  year <- as.numeric(gsub('-.*$', '', basename(filename)))
  df <- read_csv(filename, col_types = cols(grade_level=col_character(), grade_code=col_character(), admit_code=col_character(), adcode=col_character(),fall_days_present = col_character(), spring_days_present = col_character()))
  df$year <- year
  df
}

bios1 <- map_df(files, read_csv_with_year)
```

Tidy up June Bios data for modeling.
```{r}
bios2 <-
  bios1 %>%
  filter(grade_level!="AD", grade_level!="IN") %>%
  mutate(grade_level=ifelse(grade_level=="0K", 0, 
                            ifelse(grade_level=="PK", -1, 
                                   as.numeric(grade_level)))) %>%
  mutate(disability=ifelse(is.na(disability), 'ND', disability)) %>%
  mutate(perc_attendance=
           ifelse(is.na(days_abs),
                  (as.numeric(fall_days_present)+as.numeric(spring_days_present))/(fall_days_absent+spring_days_absent+as.numeric(fall_days_present)+as.numeric(spring_days_present)),
                                (days_pres+days_released)/(days_pres+days_abs+days_released)))

bios2 %>% 
  summarise(p=sum(is.na(perc_attendance))/n())
```

7% of our attendances are missing. For now, we are going to drop those rows. Later, we'll try bucketing attendance?

```{r}
load('/data/nycdoe/clean_data/tidy_grad_data.Rdata')
bios3 <-
  bios2 %>%
  filter(!is.na(perc_attendance)) 

bios4 <-
  bios3 %>%
  group_by(student_id_scram) %>%
  arrange(year) %>%
  mutate(did_continue=ifelse(!is.na(lead(grade_level)) & grade_level == lead(grade_level) - 1, 1, 0)) %>%
  ungroup() %>%
  mutate(grade_level=as.character(grade_level), year=as.character(year))

bios5 <-
  bios4 %>%
  left_join(tidy_grad, by=c('student_id_scram'))

bios6 <-
  bios5 %>%
  mutate(did_continue=ifelse(grade_level=='12', graduated, did_continue))
```

```{r}
bios6 %>% 
  group_by(grade_level) %>% 
  summarise(num_nas=sum(is.na(did_continue)), perc_nas=sum(is.na(did_continue))/n())

bios7 <-
  bios6 %>%
  group_by(student_id_scram) %>%
  filter(!any(is.na(did_continue))) %>%
  ungroup()
```

3% of 12th graders in June Bios are not listed in Grad data, so we do not know what to set the bit for them in `did_continue`. For now, we are dropping those students.

```{r}
bios8 <-
  bios7 %>%
  mutate(did_not_continue=!did_continue)

bios9 <-
  bios8 %>%
  select(did_continue, everything()) %>%
  filter(year %in% c("2005", "2006", "2007", "2008", "2009", "2010", "2011"))
```
Note: 2012-2014 don't list disability, so can't use ONLY those years with one other and have disability as a feature in the model.

Create test and train sets.
```{r}
sample_size <- floor(0.80 * nrow(bios9))

set.seed(18)
train_ind <- sample(seq_len(nrow(bios9)), size=sample_size)

train <- bios9[train_ind, ]
test <- bios9[-train_ind, ]
```

Model #2.
```{r}
train_with_features <-
  train %>%
  select(did_not_continue, grade_level, sex, ethnicity, home_lang, pob_code, ell, swd, disability, poverty, perc_attendance) 
model_data <- train_with_features %>%
  group_by_at(setdiff(names(train_with_features), "did_not_continue")) %>%
  summarize(yes = sum(did_not_continue), no = n() - sum(did_not_continue))

X_train <- model.matrix(~ grade_level + sex + ethnicity + disability + ell + poverty + perc_attendance, data=model_data)
y_train <- cbind(model_data$no, model_data$yes)

model_2 <- glmnet(X_train, y_train, family="binomial", lambda = 0)
```

##Evaluating model_2.

Distribution of our predictions.
```{r}
model_data_test <-
  test %>%
  select(did_not_continue, grade_level, sex, ethnicity, home_lang, pob_code, ell, swd, disability, poverty, perc_attendance) %>%
  group_by_at(setdiff(names(train_with_features), "did_not_continue")) %>%
  summarize(yes = sum(did_not_continue), no = n() - sum(did_not_continue))

X_test <-
  model.matrix(~ grade_level + sex + ethnicity + disability + ell + poverty + perc_attendance, data=model_data_test)

y_test <-
  cbind(model_data_test$no, model_data_test$yes)

for (col in setdiff(colnames(X_train), colnames(X_test))) {
  m <-matrix(0, nrow=nrow(X_test))
  colnames(m) <- c(col)
  X_test <- cbind(X_test, m)
}

X_test <- (X_test[,colnames(X_train)])

data.frame(p=as.numeric(predict(model_2, X_test, type="response")) ) %>% 
  ggplot(aes(x=p)) + 
  geom_histogram()
```


Calculating accuracy of our model.
```{r}
predictions_model_2 <-
  data.frame(y_test) %>%
  merge(data.frame(predict(model_2, X_test, type="response")), by="row.names")

colnames(predictions_model_2)<-c("Row.names", "cont", "did_not_cont", "p_did_not_continue")

model_2_stats <-
  predictions_model_2 %>%
  mutate(total=cont+did_not_cont, num_correct=did_not_cont*(p_did_not_continue>=0.5) + cont*(p_did_not_continue<0.5))
  
accuracy <-
  model_2_stats %>%
  summarise(accuracy=sum(num_correct)/sum(total), baseline_accuracy=sum(cont)/sum(total))

accuracy
```

```{r}
precision <-
  model_2_stats %>%
  filter(p_did_not_continue>=0.5) %>%
  summarise(prec=sum(cont)/sum(total))

precision
```

```{r}
tpr <-
  model_2_stats %>%
  summarise(tpr=sum(did_not_cont*(p_did_not_continue>=0.5))/sum(did_not_cont))

tpr
```

```{r}
fpr <-
  model_2_stats %>%
  summarise(fpr=sum(cont*(p_did_not_continue>=0.5))/sum(cont))

fpr
```

Calibration plot
```{r}
# predicted = p, actual = yes
model_2_stats %>%
  group_by(predicted=round(p_did_not_continue*10)/10) %>%
  summarise(num=sum(total), actual=sum(did_not_cont)/sum(total)) %>%
  ggplot(aes(x=predicted, y=actual, size=num)) +
  geom_point() +
  geom_abline(linetype=2) +
  scale_x_continuous(labels=percent, lim=c(0,1)) +
  scale_y_continuous(labels=percent, lim=c(0,1)) +
  scale_size_continuous(labels=comma) +
  labs(title='Calibration plot for Model 2', x='Predicted probability that student will not continue', y= 'Percent of students that actually did not continue', size='Number of students')
```

ROC curve
```{r}
roc_data_1 <- data.frame(matrix(NA, nrow = 1000, ncol = 2))
colnames(roc_data_1) <- c("tpr", "fpr")

for (i in 1:1000) {
  thresh=i/1000
  temp <-
    model_2_stats %>%
    summarise(tpr=sum(did_not_cont*(p_did_not_continue>=thresh))/sum(did_not_cont),
              fpr=sum(cont*(p_did_not_continue>=thresh))/sum(cont))

  roc_data_1[i, 'tpr'] <- temp[1, 1]
  roc_data_1[i, 'fpr'] <- temp[1, 2]
}

roc_data_1 %>%
  ggplot(aes(x=fpr, y=tpr)) +
  geom_line() +
  xlim(0, 1) +
  geom_abline(linetype='dashed')
```

Calculating the AUC
```{r}
auc <-
  model_2_stats %>%
  summarise(auc=mean(p_did_not_continue>=0.5))

auc
```
Is this correct?

## Breaking down metrics by demographics

1. By ethnicity

```{r}
X_test_new <-
  data.frame(X_test) %>%
  mutate(Row.names=row_number()) 

model_2_stats_with_x <-
  model_2_stats %>%
  mutate(Row.names=as.numeric(Row.names)) %>%
  left_join(X_test_new, by="Row.names")

model_2_stats_ethnic <-
  model_2_stats_with_x %>%
  select(2:6, grep('ethnicity', colnames(.))) %>%
  gather('ethnicity', 'value', 6:11) %>%
  filter(value==1) %>%
  group_by(ethnicity)
```

Distribution of predictions.
```{r}
model_2_stats_ethnic %>%
  ungroup() %>%
  ggplot(aes(x=p_did_not_continue)) + 
  geom_histogram() +
  facet_wrap(~ethnicity)
```

Accuracy.
```{r}
accuracy <-
  model_2_stats_ethnic %>%
  summarise(accuracy=sum(num_correct)/sum(total), baseline_accuracy=sum(cont)/sum(total))

accuracy
```

Precision.
```{r}
precision <-
  model_2_stats_ethnic %>%
  filter(p_did_not_continue>=0.5) %>%
  summarise(prec=sum(cont)/sum(total))

precision
```

True positive rate.
```{r}
tpr <-
  model_2_stats_ethnic %>%
  summarise(tpr=sum(did_not_cont*(p_did_not_continue>=0.5))/sum(did_not_cont))

tpr
```

False positive rate.
```{r}
fpr <-
  model_2_stats_ethnic %>%
  summarise(fpr=sum(cont*(p_did_not_continue>=0.5))/sum(cont))

fpr
```

Calibration plot.
```{r}
model_2_stats_ethnic %>%
  group_by(ethnicity, predicted=round(p_did_not_continue*10)/10) %>%
  summarise(num=sum(total), actual=sum(did_not_cont)/sum(total)) %>%
  ggplot(aes(x=predicted, y=actual, size=num)) +
  geom_point() +
  geom_abline(linetype=2) +
  scale_x_continuous(labels=percent, lim=c(0,1)) +
  scale_y_continuous(labels=percent, lim=c(0,1)) +
  scale_size_continuous(labels=comma) +
  labs(title='Calibration plot for Model 2', x='Predicted probability that student will not continue', y= 'Percent of students that actually did not continue', size='Number of students') +
  facet_wrap(~ethnicity)
```

2. By gender

```{r}
model_2_stats_gender <-
  model_2_stats_with_x %>%
  select(2:6, grep('sex', colnames(.))) %>%
  group_by(sexM)
```

Distribution of predictions.
```{r}
model_2_stats_gender %>%
  ungroup() %>%
  ggplot(aes(x=p_did_not_continue)) + 
  geom_histogram() +
  facet_wrap(~as.factor(sexM))
```


Accuracy.
```{r}
accuracy <-
  model_2_stats_gender %>%
  summarise(accuracy=sum(num_correct)/sum(total), baseline_accuracy=sum(cont)/sum(total))

accuracy
```

Precision.
```{r}
precision <-
  model_2_stats_gender %>%
  filter(p_did_not_continue>=0.5) %>%
  summarise(prec=sum(cont)/sum(total))

precision
```

True positive rate.
```{r}
tpr <-
  model_2_stats_gender %>%
  summarise(tpr=sum(did_not_cont*(p_did_not_continue>=0.5))/sum(did_not_cont))

tpr
```

False positive rate.
```{r}
fpr <-
  model_2_stats_gender %>%
  summarise(fpr=sum(cont*(p_did_not_continue>=0.5))/sum(cont))

fpr
```

Calibration plot.
```{r}
model_2_stats_gender %>%
  group_by(sexM, predicted=round(p_did_not_continue*10)/10) %>%
  summarise(num=sum(total), actual=sum(did_not_cont)/sum(total)) %>%
  ggplot(aes(x=predicted, y=actual, size=num)) +
  geom_point() +
  geom_abline(linetype=2) +
  scale_x_continuous(labels=percent, lim=c(0,1)) +
  scale_y_continuous(labels=percent, lim=c(0,1)) +
  scale_size_continuous(labels=comma) +
  labs(title='Calibration plot for Model 2', x='Predicted probability that student will not continue', y= 'Percent of students that actually did not continue', size='Number of students') +
  facet_wrap(~sexM)
```

## Model 3

```{r}
load('/data/nycdoe/clean_data/stud_perf_quantiledGPA.Rdata')

stud_perf_quantGPA <-
  stud_perf_quantGPA %>%
  select(year, student_id_scram, quantiled_GPA) %>%
  mutate(year=as.character(year))

bios10 <-
  bios9 %>%
  mutate(student_id_scram=as.character(student_id_scram)) %>%
  left_join(stud_perf_quantGPA, by=c('year','student_id_scram')) %>%
  filter(year %in% c("2005", "2006", "2007", "2008", "2009", "2010", "2011"))

sample_size <- floor(0.80 * nrow(bios10))

set.seed(18)
train_ind <- sample(seq_len(nrow(bios10)), size=sample_size)

train_3 <- bios10[train_ind, ]
test_3 <- bios10[-train_ind, ]
 
model_data_3 <- 
  train_3 %>%
  select(did_not_continue, grade_level, sex, ethnicity, home_lang, pob_code, ell, swd, disability, poverty, perc_attendance, quantiled_GPA) %>%
  group_by_at(setdiff(names(.), "did_not_continue")) %>%
  summarize(yes = sum(did_not_continue), no = n() - sum(did_not_continue))

X_train <- model.matrix(~ grade_level + sex + ethnicity + disability + ell + poverty + perc_attendance + quantiled_GPA, data=model_data_3)
y_train <- cbind(model_data_3$no, model_data_3$yes)

model_3 <- glmnet(X_train, y_train, family="binomial", lambda = 0)
```

##Evaluating model_3.

Distribution of our predictions.
```{r}
model_data_test_3 <-
  test_3 %>%
  select(did_not_continue, grade_level, sex, ethnicity, home_lang, pob_code, ell, swd, disability, poverty, perc_attendance, quantiled_GPA) %>%
  group_by_at(setdiff(names(.), "did_not_continue")) %>%
  summarize(yes = sum(did_not_continue), no = n() - sum(did_not_continue))

X_test <-
  model.matrix(~ grade_level + sex + ethnicity + disability + ell + poverty + perc_attendance + quantiled_GPA, data=model_data_test_3)

y_test <-
  cbind(model_data_test_3$no, model_data_test_3$yes)

for (col in setdiff(colnames(X_train), colnames(X_test))) {
  m <-matrix(0, nrow=nrow(X_test))
  colnames(m) <- c(col)
  X_test <- cbind(X_test, m)
}

X_test <- (X_test[,colnames(X_train)])

data.frame(p=as.numeric(predict(model_3, X_test, type="response")) ) %>% 
  ggplot(aes(x=p)) + 
  geom_histogram()
```


Calculating accuracy of our model.
```{r}
predictions_model_3 <-
  data.frame(y_test) %>%
  merge(data.frame(predict(model_3, X_test, type="response")), by="row.names")

colnames(predictions_model_3)<-c("Row.names", "cont", "did_not_cont", "p_did_not_continue")

model_3_stats <-
  predictions_model_3 %>%
  mutate(total=cont+did_not_cont, num_correct=did_not_cont*(p_did_not_continue>=0.5) + cont*(p_did_not_continue<0.5))
  
accuracy <-
  model_3_stats %>%
  summarise(accuracy=sum(num_correct)/sum(total), baseline_accuracy=sum(cont)/sum(total))

accuracy
```

```{r}
precision <-
  model_3_stats %>%
  filter(p_did_not_continue>=0.5) %>%
  summarise(prec=sum(cont)/sum(total))

precision
```

```{r}
tpr <-
  model_3_stats %>%
  summarise(tpr=sum(did_not_cont*(p_did_not_continue>=0.5))/sum(did_not_cont))

tpr
```

```{r}
fpr <-
  model_3_stats %>%
  summarise(fpr=sum(cont*(p_did_not_continue>=0.5))/sum(cont))

fpr
```

Calibration plot
```{r}
# predicted = p, actual = yes
model_3_stats %>%
  group_by(predicted=round(p_did_not_continue*10)/10) %>%
  summarise(num=sum(total), actual=sum(did_not_cont)/sum(total)) %>%
  ggplot(aes(x=predicted, y=actual, size=num)) +
  geom_point() +
  geom_abline(linetype=2) +
  scale_x_continuous(labels=percent, lim=c(0,1)) +
  scale_y_continuous(labels=percent, lim=c(0,1)) +
  scale_size_continuous(labels=comma) +
  labs(title='Calibration plot for Model 2', x='Predicted probability that student will not continue', y= 'Percent of students that actually did not continue', size='Number of students')
```

ROC curve
```{r}
roc_data_2 <- data.frame(matrix(NA, nrow = 1000, ncol = 2))
colnames(roc_data_2) <- c("tpr", "fpr")

for (i in 1:1000) {
  thresh=i/1000
  temp <-
    model_3_stats %>%
    summarise(tpr=sum(did_not_cont*(p_did_not_continue>=thresh))/sum(did_not_cont),
              fpr=sum(cont*(p_did_not_continue>=thresh))/sum(cont))

  roc_data_2[i, 'tpr'] <- temp[1, 1]
  roc_data_2[i, 'fpr'] <- temp[1, 2]
}

roc_data_2 %>%
  ggplot(aes(x=fpr, y=tpr)) +
  geom_line() +
  xlim(0, 1) +
  geom_abline(linetype='dashed')
```
